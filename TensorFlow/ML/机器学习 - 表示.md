## TensorFlowFlow学习笔记 —— 机器学习之表示 [【上页】](https://tinyworker.github.io/TensorFlow/index) ##

### 特征工程 ###
在进行训练之前，需要准备大量的数据，但往往我们得到的数据是不能直接应用于训练的，因此我们需要将原始数据转换为程序能识别的特征数据，这时需要做的是**特征映射**。

因为特征值在多数模型中都需要与模型权重相乘，因此都将特征表示为实数向量，称为**特征矢量**。

在映射过程，若原始数据本身是整型或浮点数的，可以直接映射无需转换，但会有分类特征，这类特征无法做直接的数值转换，需要预先转换为数值。

对于某分类特征，数据集之外的可能值都包含在“其他”分类里，称为**OOV（词汇表外）分桶**。

但是，对于分类特征，有时出现了多值，但这些多值在标签预测中可能关系不大，又或者其值在指定值不同的时候其权重又不同，这就是分类特征的两个限制。

通常为了去除限制，会为分类特征创建一个二元向量，其中对于适用于样本的值，相应的向量元素为1，其他所有元素为0。其中向量的长度等于词汇表中的元素数，当只有一个值为1时，称为**独热编码**，有多个值为1时，称为**多热编码**。

在此基础上，若存在大量不同值，仅有1-2个是1时，二元向量是非常低效的表示方法，所以用一种常用的方法是**稀疏表示法，仅存储非零值。**

### 良好特征的特点 ###
上面说了将原始数据映射到合适特征矢量的方法，那么什么才算是良好的特征矢量呢？

**避免很少使用的离散特征值**，良好的特征值应该出现约5次以上，这样模型能很好的学习该特征值如何与标签关联的，比如像房屋类型就是出现次数多的特征值，而房屋ID这种单一特征就不适合。

**最好具有清晰明确的含义**，特征对于项目都应该具有明确含义，比如房龄用年来表示，而不是某些专属的表达公式。

**实际数据内不参入特殊值**，比如某种比率范围0-1，因值为空而展示为-1这种，对于这种特殊值的特征，就要转换成两个特征，一个只存储质量比率，没有特殊值；一个存储布尔值，表示是否为空。

**考虑上游不稳定性**，特征的定义不应该随时间而改变，但收集其他模型推理的值时可能产生额外成本，就是你不确定这个当前值在未来是否会发生改变，比如用id映射的名称，该ID应用于其他模型时可能不会正确推导出映射名称。

### 数据清理 ###
这是机器学习中极其重要的一环，是确保后续动作更加准确有效的基础。因此需要花费大量的时间去剔除坏样本，并加工可弥补的样本，一点点坏数据都有可能破坏掉整个结果。

**缩放特征值**，将自然范围转换到标准范围（个位数范围），在特征集有多个特征的时候，缩放具有如下优势：

- 帮助梯度下降法更快的收敛。
- 帮助避免NaN陷阱（若有一个数值变为NaN，所有数字最终都会因运算变成NaN）。
- 帮助模型为每个特征确定合适的权重。因为特征范围越大，耗费资源越多。

**处理极端离群值**，最好的方法是取对数，对于取了对数后仍然有极端值，那么可以设置一个上限，大于该上限统一划分到某个区间。

**分箱**，将某个特征的取值范围做等额划分，每个区间都可以让模型学习不同的行为。另一种方式是按分位数分箱，能保证每个箱里的样本数量是均等的，且该方式无需担心离群值。

**清查**，实际数据可能存在遗漏值，重复样本，不良标签，不良特征值等原因，导致样本不可靠。此外，集合中的不良数据也是清查对象，直方图是可视化的良好机制，也可以使用统计信息来进行排查（最大值最小值，均值和中间值，标准偏差等）。

**了解数据**，要明确预期的数据状态，确认数据是否满足预期，检测训练数据与其他来源是否一致。

