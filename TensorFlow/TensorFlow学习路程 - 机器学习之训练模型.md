## TensorFlow学习路程 - 机器学习之训练模型 [【上页】](https://tinyworker.github.io/TensorFlow/index) ##
### 泛化（Generalization）###
泛化指的是模型经过训练后向新数据衍生的行为。在泛化过程中，若模型与训练集数据紧密联系，但在泛化到新数据的预测结果很糟糕，那么就认为模型过拟合。

过拟合，就是模型的复杂度超出数据所需程度导致的。
> 小记：泛化和过拟合实际上就是两个术语，泛化代表模型从训练集扩展到新数据的过程，过拟合是描述的在泛化中表现不好的情况。

下面有几个情况：

- 机器学习的目标，是对从真实概率分布中抽取的新数据做出良好的预测。
- 机器学习的基本冲突，是适当的拟合样本数据，但也要尽可能简单的拟合数据。
- 模型无法查看整体情况，只能从训练集中取样。
 
那么，如何的去适应上述的情况呢？
### 奥卡姆剃刀（Occam's Razor） ###
奥卡姆剃刀定律就是简约法则，是强调用较少的东西去做同样能做好的事情。适用于当前科学界，就是在各种理论中，每种都能做出同样准确的预言，那么就应该选择其中假设最少的一个。在机器学习方面，则是机器学习模型越简单，良好的实证结果就越有可能不仅仅基于样本的特性。

而现在奥卡姆剃刀已正式应用在
**统计学习理论**和**计算学习理论**
这两个领域。该领域已形成了**泛化边界**，可以用统计化描述模型的泛化能力：

- 模型的复杂程度
- 模型在处理训练数据方面的表现

因此，为了能保证模型在训练中能获得从未见过的数据，一种方法则是将数据集拆分为两个子集：训练集，测试集。

对于测试集而言，表现是否良好需要有两个大前提，一是测试集足够大，二是没有反复用测试集来测试（这样等于进入了训练集）。

### 机器学习细则 ###
有三项基本假设来阐明泛化：

- 从分布中随机抽取独立同分布的样本，即样本间不会相互影响。
- 分布式平稳的，即在数据集内不会发生变化。
- 从同一分布的数据划分中抽取样本。

但在实际中，偶尔也会违背这些假设，比如广告的定向推送，通常会基于用户是否看过某些类似的广告，这就违背了独立同分布假设；又比如某种商品的一年销售数据，用户行为会呈现季节性变化，那就违背了平稳性。

### 训练与测试，还不够 ###
将数据集划分为训练集与测试集后，为了对照泛化能力，训练集与测试集的比例是有考究的。

设定二者均为50%，依照随机生成的数据试验来看，学习速率过大（3），会导致测试集的损失更高，意味着泛化能力较差。而降低了学习速率过后（0.001），测试集损失基本接近训练损失。而是否用批量训练并没有显著差异。


然而，若将比例调整，10%训练-90%测试，在大批量或高学习速率情况下，训练集甚至于无法找到最低点而是在左右徘徊，同时测试集损失要明显高于训练集损失。

即使调整了训练集与测试集比例，但在经过几轮测试后，测试集已经不能体现出泛化差异了，因为在重复的过程中会自发的拟合测试集特性，这样就失去了测试集的意义。

那么如何解决呢？
### 验证（Validation）###
在训练集和测试集的基础上，再划分一个区间，验证集，验证集用来替代原测试集的作用来调整模型，得到最佳效果的模型后才会在测试集上确认，能更大程度的减少测试集曝光程度。

数据失效后，更好的当然是收集更多数据来刷新数据集，但某些场景中重新开始也是种很好的重置方式。

### 特征组合 ###
之前的学习里，我们使用的特征都是简单的，单一的，可以用线性规律来解释的，但是，真实场景下，也很多特征是无法用线性规律去解释，是非线性问题，这个时候，我们就会创建特征组合（Feature Crosses）。

特征组合可以有很多种类，比如：

- 【A X B】：两个特征的乘形成的组合。
- 【A X B X C X D X E】：五个特征的乘形成的组合。
- 【A X A】：单个特征的平方形成的组合。

完成了特征组合后，使用**随机梯度下降法**，能有效**训练线性模型**。

在特征组合中，我们常常会组合独热矢量，将其组合视为逻辑连接，比如国家与语言的关系，组合后的特征更具有解读性。

### 正则化（Regularization for Simplicity） ###
之前提到了过拟合，是由于模型复杂度过高导致测试集合的损失较大。那么，**我们降低复杂度来防止过拟合的过程，称为正则化**。

也就是说，不以最小化损失为目标，而是以最小化损失和复杂度为目标，称为**结构风险最小化**。因此，在训练优化算法中就包含两项内容：一个是**损失项**，用于衡量模型与数据的拟合度，一个是**正则化项**，用于衡量模型复杂度。

使用L2正则化公式来量化复杂度，此公式将正则化项定义为所有特征权重的平方和，这是将模型复杂度作为模型中所有特征的权重的函数。
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <msub>
    <mi>L</mi>
    <mn>2</mn>
  </msub>
  <mtext>&#xA0;regularization term</mtext>
  <mo>=</mo>
  <mrow class="MJX-TeXAtom-ORD">
    <mo stretchy="false">|</mo>
  </mrow>
  <mrow class="MJX-TeXAtom-ORD">
    <mo stretchy="false">|</mo>
  </mrow>
  <mi mathvariant="bold-italic">w</mi>
  <mrow class="MJX-TeXAtom-ORD">
    <mo stretchy="false">|</mo>
  </mrow>
  <msubsup>
    <mrow class="MJX-TeXAtom-ORD">
      <mo stretchy="false">|</mo>
    </mrow>
    <mn>2</mn>
    <mn>2</mn>
  </msubsup>
  <mo>=</mo>
  <mrow class="MJX-TeXAtom-ORD">
    <msubsup>
      <mi>w</mi>
      <mn>1</mn>
      <mn>2</mn>
    </msubsup>
    <mo>+</mo>
    <msubsup>
      <mi>w</mi>
      <mn>2</mn>
      <mn>2</mn>
    </msubsup>
    <mo>+</mo>
    <mo>.</mo>
    <mo>.</mo>
    <mo>.</mo>
    <mo>+</mo>
    <msubsup>
      <mi>w</mi>
      <mi>n</mi>
      <mn>2</mn>
    </msubsup>
  </mrow>
</math>
可以看到此公式中，接近于0的权重对模型复杂度几乎没有影响，但离群值权重则可能产生巨大影响。

### lambda - 正则化率 ###
在正则化的计算中，我们会将正则化项的值乘以标量，目的是增加正则化效果，在L2正则化后，模型权重值接近于0，且平均值接近于0，呈正态分布。

在选择lambda值时，目标是在简单化和训练数据拟合间找到平衡。如果lambda值过高，则模型会很简单，但会有欠拟合的风险，可能训练集效果不理想；如果lambda值过低，则模型会比较复杂，会有过拟合的风险，可能有无法泛化的问题。