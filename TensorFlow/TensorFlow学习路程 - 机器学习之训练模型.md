## TensorFlow学习路程 - 机器学习之训练模型 ##
### 泛化（Generalization）###
泛化指的是模型经过训练后向新数据衍生的行为。在泛化过程中，若模型与训练集数据紧密联系，但在泛化到新数据的预测结果很糟糕，那么就认为模型过拟合。

过拟合，就是模型的复杂度超出数据所需程度导致的。
> 小记：泛化和过拟合实际上就是两个术语，泛化代表模型从训练集扩展到新数据的过程，过拟合是描述的在泛化中表现不好的情况。

下面有几个情况：

- 机器学习的目标，是对从真实概率分布中抽取的新数据做出良好的预测。
- 机器学习的基本冲突，是适当的拟合样本数据，但也要尽可能简单的拟合数据。
- 模型无法查看整体情况，只能从训练集中取样。
 
那么，如何的去适应上述的情况呢？
### 奥卡姆剃刀（Occam's Razor） ###
奥卡姆剃刀定律就是简约法则，是强调用较少的东西去做同样能做好的事情。适用于当前科学界，就是在各种理论中，每种都能做出同样准确的预言，那么就应该选择其中假设最少的一个。在机器学习方面，则是机器学习模型越简单，良好的实证结果就越有可能不仅仅基于样本的特性。

而现在奥卡姆剃刀已正式应用在
**统计学习理论**和**计算学习理论**
这两个领域。该领域已形成了**泛化边界**，可以用统计化描述模型的泛化能力：

- 模型的复杂程度
- 模型在处理训练数据方面的表现

因此，为了能保证模型在训练中能获得从未见过的数据，一种方法则是将数据集拆分为两个子集：训练集，测试集。

对于测试集而言，表现是否良好需要有两个大前提，一是测试集足够大，二是没有反复用测试集来测试（这样等于进入了训练集）。

### 机器学习细则 ###
有三项基本假设来阐明泛化：

- 从分布中随机抽取独立同分布的样本，即样本间不会相互影响。
- 分布式平稳的，即在数据集内不会发生变化。
- 从同一分布的数据划分中抽取样本。

但在实际中，偶尔也会违背这些假设，比如广告的定向推送，通常会基于用户是否看过某些类似的广告，这就违背了独立同分布假设；又比如某种商品的一年销售数据，用户行为会呈现季节性变化，那就违背了平稳性。

### 训练与测试，还不够 ###
将数据集划分为训练集与测试集后，为了对照泛化能力，训练集与测试集的比例是有考究的。

设定二者均为50%，依照随机生成的数据试验来看，学习速率过大（3），会导致测试集的损失更高，意味着泛化能力较差。而降低了学习速率过后（0.001），测试集损失基本接近训练损失。而是否用批量训练并没有显著差异。


然而，若将比例调整，10%训练-90%测试，在大批量或高学习速率情况下，训练集甚至于无法找到最低点而是在左右徘徊，同时测试集损失要明显高于训练集损失。

即使调整了训练集与测试集比例，但在经过几轮测试后，测试集已经不能体现出泛化差异了，因为在重复的过程中会自发的拟合测试集特性，这样就失去了测试集的意义。

那么如何解决呢？
### 验证（Validation）###
在训练集和测试集的基础上，再划分一个区间，验证集，验证集用来替代原测试集的作用来调整模型，得到最佳效果的模型后才会在测试集上确认，能更大程度的减少测试集曝光程度。

数据失效后，更好的当然是收集更多数据来刷新数据集，但某些场景中重新开始也是种很好的重置方式。
